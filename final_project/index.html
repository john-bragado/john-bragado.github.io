<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CS184/284A Project</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Inter', sans-serif;
      line-height: 1.6;
      color: #32323a;
      margin: 0;
      background-color: #ffffff;
    }

    h1 {
      text-align: center;
      font-size: 40px;
      margin: 40px 0;
    }

    h2 {
      font-size: 28px;
      margin-top: 60px;
      margin-bottom: 20px;
      border-bottom: 2px solid #eee;
      padding-bottom: 6px;
    }

    p {
      font-size: 13px;
      margin-bottom: 20px;
    }

    figure {
      display: inline-block;
      text-align: center;
      margin: 0;
    }

    figcaption {
      text-align: center;
      font-size: 12px;
      margin-top: 4px;
    }



    .container {
      margin: 0 auto;
      padding: 40px 10%;
      max-width: 900px;
    }
  </style>
</head>

<body>
  <div class="container">
    <header>
      <h1>Dawn to Dust: Ray Tracing with Volumetric Lighting</h1>
    </header>

    <main>
      <h2>Abstract</h2>
      <p>
        Our project is about implementing ray scattering to enable more realistic volumetric lighting in scenes. In
        homework 3, we implemented a pathtracer that allowed us to emulate realistic lighting by generating rays that
        shoot from the camera to surfaces throughout the scene, allowing them to bounce repeatedly and accumulate
        luminance. We built off of that assignment by, rather than shooting rays that travel until hitting an object,
        enabling randomized opportunities for the rays to interact with the medium they are traveling through and bounce
        in a different direction. With a full implementation, we can display a light fog covering our scene that creates
        light shafts when exposed to light sources.
      </p>

      <h2>Technical Approach</h2>
      <p>
        To implement ray scattering, we sample from a Poisson distribution for each ray to get a random length s. This
        is used to simulate the probability of a light ray interacting with a medium. The radiance for the ray can then
        be calculated from four components: Absorption, Emission, Out-scattering, and In-scattering.

      </p>
      <p>

        Our implementation is a combination and a subset of the work by Lafortune and Willems. The difference being that
        due to time limitations, we currently don’t have the bidirectional and non-homogeneous medium support.
        Furthermore, we chose not to include emission as it is more used for simulation mediums that glow by itself such
        as fire which is different from the fog effect we want to create. For absorption we will need to model as ray
        travels through the air, it will partially absorb some of the energy so the light will lose energy along its
        original path. As for the out scattering, it is how part of ray energy scattering away from the original path
        also causes ray to lose energy along its original path. Lastly, for scattering, it describes how the lights will
        gain energy as the energy of other rays scatter toward the ray we are focusing on, causing the ray to gain
        energy at the direction we are looking at.

      </p>
      <p>

        From homework 3, we built a monte carlo pathtracer renderer that only renders the surfaces of objects. To add
        volumetric rendering functionality on top of this, we will need to translate the physical aspects / properties
        of mediums such as fog to a monte carlo version. Speaking broadly, we accomplish this by modeling luminance
        falloff using transmission, sampling scattering distances with inverse CDF sampling, and modeling bounces using
        phase functions. To improve the convergence rate of our renders, we also implemented phase function sampling vs
        importance sampling for volumetric path tracing (which is somewhat similar to importance sampling for surfaces).

      </p>
      <p>

        In real life, light loses energy as it passes through gasses as light interacts with particles in the air.
        Imagine a single ray of light passing through a medium, eventually it will hit a particle and be absorbed or
        reflected in some direction. However, not all photons in that ray of light will reach this far, some will
        inevitably be absorbed or deflected away throughout this distance. In our code, we model this interaction
        distance using inverse CDF sampling. Then, once we determine this interaction distance, we calculate the
        transmittance between the origin of the ray and this distance to calculate how much light has made it to this
        scattering distance. In addition, at this distance, light could be either scattered or absorbed. Thus, we weight
        the light we receive by bouncing by the albedo, which measures the probability of a ray being scattered given
        that an interaction has occurred.

      </p>
      <p>

        If this light gets scattered, we will use inverse CDF sampling on the phase function to determine which way the
        light is reflected. This phase function is essentially a mathematical model for how particles tend to scatter
        light in the real world. Some materials tend to let light through more, which means that the light is more
        likely to continue going forwards, while some act the opposite way. We implemented the Henyey-Greenstein and
        Isotropic phase functions. However, much like our hemisphere sample method in homework 3, this method might be
        physically correct but does not converge nearly as fast as we would like. Thus, we created an importance
        sampling method, where we intentionally sample towards light sources, and unbias those samples by weighing these
        samples with the probability of the phase function sampling in this direction.

      </p>
      <p>


        <b>Challenges / Problems Encountered:</b> One of the first issues we ran into was determining whether our
        absorption and outscattering were working properly due to the lack of in-scattering color. We used a temporary
        color to help visualize progress. Another issue was importing scenes from Blender. There were many
        inconsistencies, so we tried to keep scenes as simple as possible. During the early stages, we speculated that
        the newly introduced extinction made indirect lighting require much more computation. Furthermore, volumetric
        scattering caused the adaptive sampling to converge much quicker, causing more solid black regions. We chose to
        disable adaptive sampling.

      </p>
      <p>


        <b>Lessons Learned:</b> Since we are trying to model a physically accurate situation, our intuition of the
        physical world is important. We learned that probability is a very important part of the estimation, and
        figuring out the PDF and keeping all the estimations unbiased is easy to mess up and hard to debug.

      </p>

      <h2>Results</h2>
      <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 20px;">
        <figure>
          <img src="spotlightLeft2 (1).png" width="250px" />
          <figcaption></figcaption>
        </figure>
        <figure>
          <img src="CubesS0.15A0.png" width="250px" />
          <figcaption></figcaption>
        </figure>
        <figure>
          <img src="twoLights.png" width="250px" />
          <figcaption></figcaption>
        </figure>
        <figure>
          <img src="ezgif.com-animated-gif-maker (1).gif" width="400px" />
          <figcaption>Regular Ray Tracing</figcaption>
        </figure>
        <figure>
          <img src="bunnywindow (1).gif" width="400x" />
          <figcaption>Volumetric Lighting Enabled</figcaption>
        </figure>
        <figure>
          <img src="output_frame_14.png" width="500px" />
          <figcaption></figcaption>
        </figure>
      </div>


      <h2>References</h2>
      <p>Bo Sun, Ravi Ramamoorthi, Srinivasa Narasimhan, Shree K. Nayar (2005). A Practical Analytic Single Scattering
        Model for Real Time Rendering. ACM Transactions on Graphics (SIGGRAPH 2005), 24(3). Retrieved from
        https://cseweb.ucsd.edu/~ravir/papers/singlescat/scattering.pdf
      </p>
      <p>
        Jarosz, W. (2008). Efficient Monte Carlo methods for light transport in scattering media (Doctoral dissertation,
        UC San Diego). Chapter 4. Retrieved from
        https://cs.dartmouth.edu/~wjarosz/publications/dissertation/chapter4.pdf
      </p>
      <p>
        Lafortune, E.P., Willems, Y.D. (1996). Rendering Participating Media with Bidirectional Path Tracing. In: Pueyo,
        X., Schröder, P. (eds) Rendering Techniques '96. EGSR 1996. Eurographics. Springer, Vienna.
        http://luthuli.cs.uiuc.edu/~daf/courses/rendering/papers/lafortune96rendering.pdf
      </p>

    </main>
  </div>

</body>

</html>